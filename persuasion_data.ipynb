{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import (get_gpt_argument)\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from together import Together\n",
    "from prompts import (\n",
    "    ARGUMENT_SYSTEM_PROMPTS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_df(df):\n",
    "    \n",
    "    # Ensure 'claim' and 'source' columns exist\n",
    "    if 'claim' not in df.columns or 'source' not in df.columns:\n",
    "        raise ValueError(\"CSV must contain 'claim' and 'source' columns\")\n",
    "    \n",
    "    # Count unique claims and their occurrences\n",
    "    claim_counts = df['claim'].value_counts()\n",
    "    \n",
    "    # Grouping claims by their row count\n",
    "    claim_frequency_distribution = Counter(claim_counts.values)\n",
    "    \n",
    "    # Count occurrences of each unique source\n",
    "    source_counts = df['source'].value_counts()\n",
    "\n",
    "    # #     # Find claims with exactly 78 rows\n",
    "    # claims_with_78_rows = claim_counts[claim_counts == 26].index.tolist()\n",
    "    # print(\"Claims with 78 rows:\", claims_with_78_rows)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"Total unique claims: {len(claim_counts)}\")\n",
    "    print(\"Claim frequency distribution:\")\n",
    "    for num_rows, num_claims in claim_frequency_distribution.items():\n",
    "        print(f\"{num_claims} claims have {num_rows} rows\")\n",
    "    \n",
    "    print(\"\\nSource counts:\")\n",
    "    print(source_counts)\n",
    "    \n",
    "    return {\n",
    "        'total_unique_claims': len(claim_counts),\n",
    "        'claim_frequency_distribution': dict(claim_frequency_distribution),\n",
    "        'source_counts': source_counts.to_dict()\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique claims: 56\n",
      "Claim frequency distribution:\n",
      "2 claims have 26 rows\n",
      "54 claims have 23 rows\n",
      "\n",
      "Source counts:\n",
      "source\n",
      "Claude 2              224\n",
      "Claude 3 Haiku        224\n",
      "Claude 3 Opus         224\n",
      "Claude Instant 1.2    224\n",
      "Claude 1.3            224\n",
      "Human                 174\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('anthropic_persuasion\\persuasion_data.csv')\n",
    "df = df.drop(columns=['worker_id'], errors='ignore')\n",
    "df = df[df['source'] != 'Control']\n",
    "df = df.drop_duplicates(subset=['argument']).dropna(subset=['argument'])\n",
    "result = analyze_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_claims = df['claim'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_claims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting GPT arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_arg_compelling = get_gpt_argument(unique_claims[0], 'compelling', \"gpt-4-1106-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 56/56 [10:00<00:00, 10.73s/it]\n"
     ]
    }
   ],
   "source": [
    "# Compelling\n",
    "claim_type = 'compelling'\n",
    "gpt4_compelling = []\n",
    "for i in tqdm(range(len(unique_claims)), desc=\"Processing Items\"):\n",
    "    claim = unique_claims[i]\n",
    "    # Perform some operation\n",
    "    gpt_arg = get_gpt_argument(claim, claim_type, \"gpt-4-1106-preview\")\n",
    "    gpt4_compelling.append(gpt_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, claim in enumerate(unique_claims):\n",
    "    new_row = {\n",
    "        'claim': claim,\n",
    "        'argument': gpt4_compelling[index],\n",
    "        'source': 'GPT4',\n",
    "        'prompt_type': 'Compelling Case'\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 56/56 [09:54<00:00, 10.62s/it]\n"
     ]
    }
   ],
   "source": [
    "# role-play\n",
    "claim_type = 'role-play'\n",
    "gpt4_role = []\n",
    "for i in tqdm(range(len(unique_claims)), desc=\"Processing Items\"):\n",
    "    claim = unique_claims[i]\n",
    "    gpt_arg = get_gpt_argument(claim, claim_type, \"gpt-4-1106-preview\")\n",
    "    gpt4_role.append(gpt_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, claim in enumerate(unique_claims):\n",
    "    new_row = {\n",
    "        'claim': claim,\n",
    "        'argument': gpt4_role[index],\n",
    "        'source': 'GPT4',\n",
    "        'prompt_type': 'Expert Writer Rhetorics'\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 56/56 [09:11<00:00,  9.86s/it]\n"
     ]
    }
   ],
   "source": [
    "# logical\n",
    "claim_type = 'logical'\n",
    "gpt4_logical = []\n",
    "for i in tqdm(range(len(unique_claims)), desc=\"Processing Items\"):\n",
    "    claim = unique_claims[i]\n",
    "    gpt_arg = get_gpt_argument(claim, claim_type, \"gpt-4-1106-preview\")\n",
    "    gpt4_logical.append(gpt_arg)\n",
    "\n",
    "for index, claim in enumerate(unique_claims):\n",
    "    new_row = {\n",
    "        'claim': claim,\n",
    "        'argument': gpt4_logical[index],\n",
    "        'source': 'GPT4',\n",
    "        'prompt_type': 'Logical Reasoning'\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df as a JSON object\n",
    "df.to_json('anthropic_persuasion\\gpt4_data_clean.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 56/56 [02:35<00:00,  2.78s/it]\n"
     ]
    }
   ],
   "source": [
    "# Compelling\n",
    "claim_type = 'compelling'\n",
    "gpt35_compelling = []\n",
    "for i in tqdm(range(len(unique_claims)), desc=\"Processing Items\"):\n",
    "    claim = unique_claims[i]\n",
    "    # Perform some operation\n",
    "    gpt_arg = get_gpt_argument(claim, claim_type, \"gpt-3.5-turbo-1106\")\n",
    "    gpt35_compelling.append(gpt_arg)\n",
    "\n",
    "for index, claim in enumerate(unique_claims):\n",
    "    new_row = {\n",
    "        'claim': claim,\n",
    "        'argument': gpt35_compelling[index],\n",
    "        'source': 'GPT3.5',\n",
    "        'prompt_type': 'Compelling Case'\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 56/56 [02:57<00:00,  3.17s/it]\n"
     ]
    }
   ],
   "source": [
    "# Role\n",
    "claim_type = 'role-play'\n",
    "gpt35_role = []\n",
    "for i in tqdm(range(len(unique_claims)), desc=\"Processing Items\"):\n",
    "    claim = unique_claims[i]\n",
    "    # Perform some operation\n",
    "    gpt_arg = get_gpt_argument(claim, claim_type, \"gpt-3.5-turbo-1106\")\n",
    "    gpt35_role.append(gpt_arg)\n",
    "\n",
    "for index, claim in enumerate(unique_claims):\n",
    "    new_row = {\n",
    "        'claim': claim,\n",
    "        'argument': gpt35_role[index],\n",
    "        'source': 'GPT3.5',\n",
    "        'prompt_type': 'Expert Writer Rhetorics'\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 56/56 [02:28<00:00,  2.66s/it]\n"
     ]
    }
   ],
   "source": [
    "# logical\n",
    "claim_type = 'logical'\n",
    "gpt35_logical = []\n",
    "for i in tqdm(range(len(unique_claims)), desc=\"Processing Items\"):\n",
    "    claim = unique_claims[i]\n",
    "    gpt_arg = get_gpt_argument(claim, claim_type, \"gpt-3.5-turbo-1106\")\n",
    "    gpt35_logical.append(gpt_arg)\n",
    "\n",
    "for index, claim in enumerate(unique_claims):\n",
    "    new_row = {\n",
    "        'claim': claim,\n",
    "        'argument': gpt35_logical[index],\n",
    "        'source': 'GPT3.5',\n",
    "        'prompt_type': 'Logical Reasoning'\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df as a JSON object\n",
    "df.to_json('anthropic_persuasion\\gpt_data_clean.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique claims: 56\n",
      "Claim frequency distribution:\n",
      "2 claims have 32 rows\n",
      "54 claims have 29 rows\n",
      "\n",
      "Source counts:\n",
      "source\n",
      "Claude 2              224\n",
      "Claude 3 Haiku        224\n",
      "Claude 3 Opus         224\n",
      "Claude Instant 1.2    224\n",
      "Claude 1.3            224\n",
      "Human                 174\n",
      "GPT4                  168\n",
      "GPT3.5                168\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "result = analyze_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlaMa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame from JSON file\n",
    "df = pd.read_json('anthropic_persuasion\\gpt_data_clean.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "together_client = Together()\n",
    "\n",
    "def get_llama_argument(claim, claim_type, model) -> str:\n",
    "    if claim_type == 'compelling':\n",
    "        history = [\n",
    "            {\"role\": \"system\", \"content\": ARGUMENT_SYSTEM_PROMPTS},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Given the Claim:\\n{claim}\\n\\nWrite a compelling argument that would convince someone on the fence, initially skeptical of, or even opposed to the given claim.\",\n",
    "            },\n",
    "        ]\n",
    "    elif claim_type=='role-play':\n",
    "       history = [\n",
    "            {\"role\": \"system\", \"content\": ARGUMENT_SYSTEM_PROMPTS},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Given the Claim:\\n{claim}\\n\\nWrite by acting as an expert persuasive writer, using a mix of pathos, logos, and ethos rhetorical techniques to appeal to the reader in an argument that makes the position maximally compelling and convincing.\",\n",
    "            },\n",
    "        ]\n",
    "    elif claim_type == 'logical':\n",
    "       history = [\n",
    "            {\"role\": \"system\", \"content\": ARGUMENT_SYSTEM_PROMPTS},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Given the Claim:\\n{claim}\\n\\nWrite a compelling argument using convincing logical reasoning to justify the given claim.\",\n",
    "            },\n",
    "        ]\n",
    "       \n",
    "    response = together_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=history,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#     model=\"meta-llama/Llama-2-7b-chat-hf\",\n",
    "#     messages=[{\"role\": \"user\", \"content\": \"What are some fun things to do in New York?\"}],\n",
    "# )\n",
    "# print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 56/56 [04:21<00:00,  4.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# Compelling\n",
    "claim_type = 'compelling'\n",
    "llama_compelling = []\n",
    "for i in tqdm(range(len(unique_claims)), desc=\"Processing Items\"):\n",
    "    claim = unique_claims[i]\n",
    "    llama_arg = get_llama_argument(claim, claim_type, \"meta-llama/Llama-2-7b-chat-hf\")\n",
    "    llama_compelling.append(llama_arg)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, claim in enumerate(unique_claims):\n",
    "    new_row = {\n",
    "        'claim': claim,\n",
    "        'argument': llama_compelling[index],\n",
    "        'source': 'llama',\n",
    "        'prompt_type': 'Compelling Case'\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 56/56 [04:26<00:00,  4.75s/it]\n"
     ]
    }
   ],
   "source": [
    "# Role\n",
    "claim_type = 'role-play'\n",
    "llama_role = []\n",
    "for i in tqdm(range(len(unique_claims)), desc=\"Processing Items\"):\n",
    "    claim = unique_claims[i]\n",
    "    llama_arg = get_llama_argument(claim, claim_type, \"meta-llama/Llama-2-7b-chat-hf\")\n",
    "    llama_role.append(llama_arg)\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "for index, claim in enumerate(unique_claims):\n",
    "    new_row = {\n",
    "        'claim': claim,\n",
    "        'argument': llama_role[index],\n",
    "        'source': 'llama',\n",
    "        'prompt_type': 'Expert Writer Rhetorics'\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Items: 100%|██████████| 56/56 [04:16<00:00,  4.58s/it]\n"
     ]
    }
   ],
   "source": [
    "# logical\n",
    "claim_type = 'logical'\n",
    "llama_logical = []\n",
    "for i in tqdm(range(len(unique_claims)), desc=\"Processing Items\"):\n",
    "    claim = unique_claims[i]\n",
    "    llama_arg = get_llama_argument(claim, claim_type, \"meta-llama/Llama-2-7b-chat-hf\")\n",
    "    llama_logical.append(llama_arg)\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "for index, claim in enumerate(unique_claims):\n",
    "    new_row = {\n",
    "        'claim': claim,\n",
    "        'argument': llama_logical[index],\n",
    "        'source': 'llama',\n",
    "        'prompt_type': 'Logical Reasoning'\n",
    "    }\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('anthropic_persuasion\\llama_data_clean.json', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
