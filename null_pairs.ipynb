{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_data, SOURCES, save_to_json, load_from_json\n",
    "from models import (\n",
    "    get_gpt_recognition_logprobs,\n",
    "    get_model_choice,\n",
    "    get_logprobs_choice_with_sources,\n",
    "    get_gpt_score,\n",
    "    get_gpt_summary_similarity,\n",
    "    get_gpt_paraphrase,\n",
    "    get_gpt_choice_null_baseline\n",
    ")\n",
    "\n",
    "from math import exp\n",
    "from pprint import pprint\n",
    "from random import shuffle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gpt_detect_null(\n",
    "    dataset,\n",
    "    model,\n",
    "    comparison_models,\n",
    "    shuffle=True,\n",
    "    starting_idx=500,\n",
    "    ending_idx = 1000\n",
    "):\n",
    "    exact_model = model\n",
    "\n",
    "    responses, articles, keys = load_data(dataset)\n",
    "\n",
    "    results = []  \n",
    "\n",
    "    for key in tqdm(keys[starting_idx:ending_idx], desc=\"Processing keys\"):\n",
    "        article = articles[key]\n",
    "        first_summary = responses[comparison_models[0]][key]\n",
    "        second_summary = responses[comparison_models[1]][key]\n",
    "        # Shuffle at every key\n",
    "        if shuffle:\n",
    "            summaries = [first_summary, second_summary]\n",
    "            random.shuffle(summaries)\n",
    "            first_summary, second_summary = summaries\n",
    "        \n",
    "        result = {\"key\": key}\n",
    "\n",
    "        try:\n",
    "            forward_result = get_gpt_choice_null_baseline(\n",
    "                first_summary,\n",
    "                second_summary,\n",
    "                article,\n",
    "                return_logprobs=True,\n",
    "            )\n",
    "\n",
    "            if shuffle:\n",
    "                logprob_for_3 = next((item.logprob for item in forward_result if item.token == '3'), None) # item.token 1 or 2 for GT, 3 for null.\n",
    "            else:\n",
    "                logprob_for_3 = next((item.logprob for item in forward_result if item.token == '1'), None) # item.token 1 or 2 for GT, 3 for null.\n",
    "            result[\"detection_score\"] = exp(logprob_for_3)\n",
    "\n",
    "        except ValueError:\n",
    "            print('Error:', key)\n",
    "        \n",
    "        results.append(result)\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gpt4\n",
      "['gpt4', 'gpt35']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing keys: 100%|██████████| 500/500 [04:20<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4_results_null_pair_gpt4_gpt35.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [\"gpt4\"]:\n",
    "    \n",
    "    print(f\"Starting {model}\")\n",
    "    comparison_models =  [\"gpt4\", \"gpt35\"] ## Change for the two models\n",
    "    print(comparison_models)\n",
    "    #shuffle=False for GT\n",
    "    results = generate_gpt_detect_null(\n",
    "        \"cnn\", model,comparison_models, shuffle=False, starting_idx=500\n",
    "    )\n",
    "    #Save results\n",
    "    file_name = f\"{model}_results_null_pair_{comparison_models[0]}_{comparison_models[1]}.json\"\n",
    "    print(file_name)\n",
    "    path = os.path.join(\"results\",\"cnn\",\"null_pair\",file_name)\n",
    "    save_to_json(results,path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When Neither Pairs are yours but you have to pick one (False Pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how good GPT is at recognizing first model as its own (both wrong)\n",
    "def generate_gpt_detect_recognition_false_pair(\n",
    "    dataset,\n",
    "    model,\n",
    "    comparison_models,\n",
    "    starting_idx=0\n",
    "):\n",
    "\n",
    "    # For retrieving summaries, the specific fine-tuning version isn't needed\n",
    "    exact_model = model\n",
    "    model = \"gpt35\" if model.endswith(\"gpt35\") else model\n",
    "\n",
    "    responses, articles, keys = load_data(dataset)\n",
    "    results = []  \n",
    "    switch = False # shuffle between the two comparison models\n",
    "\n",
    "    for key in tqdm(keys[starting_idx:], desc=\"Processing keys\"):\n",
    "        article = articles[key]\n",
    "        first_summary = responses[comparison_models[0]][key]\n",
    "        second_summary = responses[comparison_models[1]][key]\n",
    "        \n",
    "        if switch:\n",
    "             first_summary, second_summary = second_summary, first_summary\n",
    "\n",
    "        switch = not switch # flip every iteration, first iteration is False\n",
    "\n",
    "        result = {\"key\": key}\n",
    "        forward_result = get_model_choice(\n",
    "            first_summary,\n",
    "            second_summary,\n",
    "            article,\n",
    "            \"detection\",\n",
    "            exact_model,\n",
    "            return_logprobs=True,\n",
    "        )\n",
    "        if not switch:\n",
    "            logprob = next((item.logprob for item in forward_result if item.token == '1'), None) \n",
    "        else:\n",
    "            logprob = next((item.logprob for item in forward_result if item.token == '2'), None) \n",
    "        \n",
    "        result[\"detection_score\"] = exp(logprob)\n",
    "        results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gpt4\n",
      "['gpt35', 'human']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing keys: 100%|██████████| 500/500 [05:04<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4_results_false_pair_gpt35_human.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [\"gpt4\"]:\n",
    "    \n",
    "    print(f\"Starting {model}\")\n",
    "    comparison_models =  [\"gpt35\", \"human\"] ## Change for the two models\n",
    "    print(comparison_models)\n",
    "    results = generate_gpt_detect_recognition_false_pair(\n",
    "        \"cnn\", model,comparison_models,  starting_idx=500\n",
    "    )\n",
    "    #Save results\n",
    "    file_name = f\"{model}_results_false_pair_{comparison_models[0]}_{comparison_models[1]}.json\"\n",
    "    print(file_name)\n",
    "    path = os.path.join(\"results\",\"cnn\",\"null_pair\",file_name)\n",
    "    save_to_json(results,path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
