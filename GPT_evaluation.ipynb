{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install nltk\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\G34371231\\\\OneDrive - The George Washington University\\\\Desktop\\\\self_recognition'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import load_data, SOURCES, save_to_json, load_from_json\n",
    "from models import (\n",
    "    get_gpt_recognition_logprobs,\n",
    "    get_model_choice,\n",
    "    get_logprobs_choice_with_sources,\n",
    "    get_gpt_score,\n",
    "    get_gpt_summary_similarity_index,\n",
    ")\n",
    "\n",
    "from math import exp\n",
    "from pprint import pprint\n",
    "from random import shuffle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import openai\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonym Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "random.seed(123)\n",
    "all_words = [] #need to have different lists depending on method\n",
    "all_syn = []\n",
    "\n",
    "def ind_syn_ChatGPT(replacement_word):\n",
    "    #just returns the synonym provided by ChatGPT \n",
    "    #may wish to try system message where i describe desire behavior rather than in the prompt.\n",
    "    \n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f'Provide a synonym for the word \"{replacement_word}\". Your response should strictly be the synonym, so that it may immediately replace the original word within some sentence. If you don not find a synonym just return the original word.'\n",
    "            }\n",
    "        ]\n",
    ")\n",
    "\n",
    "    #synonym = completion['choices'][0]['message']['content'].strip()\n",
    "    #synonym = completion.choices[0].message['content'].strip()\n",
    "    synonym = completion.choices[0].message.content.lower()\n",
    "    return synonym\n",
    "\n",
    "def syn_from_contxt_ChatGPT(replacement_phrase):\n",
    "    #performs synonym replacement with context. The replacement_phrase can be the entire sentence of the word to be replaced, or it can be a smaller phrase.\n",
    "    \n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\") # nosec\n",
    "        \n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that rewrites phrases by replacing words surrounded by square brackets with synonyms while preserving context and meaning.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f' \"There are word(s) in this phrase surrounded by square brackets []. Replace the words with their synonyms and get rid of the brackets. Your response is strictly the new phrase containing the synonyms. The phrase is: {replacement_phrase}'\n",
    "            }\n",
    "        ]\n",
    ")\n",
    "    synonym = completion.choices[0].message.content\n",
    "    return synonym\n",
    "\n",
    "def get_synonyms(word):\n",
    "    \"\"\"\n",
    "    Finds and returns synonyms for a given word using WordNet.\n",
    "    This function takes a word as input, searches for its synonyms \n",
    "    using the WordNet synsets, and returns a list of synonyms.\n",
    "\n",
    "    Args:\n",
    "        word (str): The word for which to find synonyms.\n",
    "    Returns:\n",
    "        list: A list of synonyms for the input word. Returns an \n",
    "              empty list if no synonyms are found.\n",
    "    \"\"\"\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for name in syn.lemma_names():\n",
    "            # Exclude the original word to avoid replacing it with itself\n",
    "            name = name.replace('_',' ')\n",
    "            if name.lower() != word.lower():\n",
    "                synonyms.append(name)\n",
    "    return synonyms\n",
    "\n",
    "def sample_words(words_alpha, num_words_to_replace):\n",
    "    # Randomly sample words to replace - i use 2x words just to account for words without synonym\n",
    "    idx_words = random.sample(list(enumerate(words_alpha)), min(2*num_words_to_replace, len(words_alpha)))\n",
    "    chosen_indices = []\n",
    "    words_to_replace = []\n",
    "    for pair in idx_words:\n",
    "        chosen_indices.append(pair[0])\n",
    "        words_to_replace.append(pair[1])  \n",
    "      \n",
    "    #idx_words is the list of words selected paired with their index in original sentence/phrase\n",
    "    #example: \"This is a test sentence to see which words get sampled, and what is returned by the replacement function.\"\n",
    "    #(1, 'is'), (8, 'words'), (2, 'a'), (13, 'is'), (4, 'sentence'), (18, 'function'), (0, 'This'), (6, 'see'), (17, 'replacement'), (10, 'sampled')\n",
    "    return chosen_indices, words_to_replace\n",
    "\n",
    "def replace_words_WordNet(sentence, num_words_to_replace):\n",
    "    \"\"\"\n",
    "    Replaces a specified number of words in a sentence with their synonyms using\n",
    "    the WordNet library, and then using ChatGPT. \n",
    "\n",
    "    This function takes a sentence and an integer specifying the number of words \n",
    "    to replace with synonyms. It randomly samples 2x the required number of words \n",
    "    to ensure replacements are possible even if some words do not have synonyms.\n",
    "    It uses the `get_synonyms` function to find synonyms for each sampled word,\n",
    "    and replaces words in the sentence until the specified number is reached.\n",
    "\n",
    "    Args:\n",
    "        sentence (str): The input sentence from which words will be replaced.\n",
    "        num_words_to_replace (int): The number of words in the sentence to be replaced by synonyms.\n",
    "\n",
    "    Returns:\n",
    "        str: The modified sentence with the specified number of words replaced by synonyms.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tokenize the sentence\n",
    "    words = word_tokenize(sentence)\n",
    "    # Filter out non-alphabetic tokens (like punctuation)\n",
    "    words_alpha = [word for word in words if word.isalpha()]\n",
    "    \n",
    "    # Randomly sample words to replace - i use 2x words just to account for words without synonym\n",
    "    indices, words_to_replace = sample_words(words_alpha, num_words_to_replace)\n",
    "    #print(words_to_replace)\n",
    "    #print(indices)\n",
    "    # Create a new sentence with synonyms replaced\n",
    "    words_replaced = 0\n",
    "    new_sentence = []\n",
    "    for word in words:\n",
    "        if word in words_to_replace and words_alpha.index(word) in indices:\n",
    "            synonyms = get_synonyms(word)\n",
    "            if synonyms and words_replaced < num_words_to_replace:\n",
    "                # Replace with a random synonym\n",
    "                new_word = random.choice(synonyms)\n",
    "                new_sentence.append(new_word)\n",
    "                #operational\n",
    "                all_words.append(word)\n",
    "                all_syn.append(synonyms)\n",
    "                words_replaced +=1\n",
    "            else:\n",
    "                # If no synonym is found, keep the original word\n",
    "                new_sentence.append(word)\n",
    "        else:\n",
    "            new_sentence.append(word)\n",
    "    \n",
    "    return ' '.join(new_sentence)\n",
    "    \n",
    "def replace_words_ChatGPT(sentence,num_words_to_replace):\n",
    "    #function to perform synonym replacement for individual words, without context provided\n",
    "    # Tokenize the sentence\n",
    "    words = word_tokenize(sentence)\n",
    "    # Filter out non-alphabetic tokens (like punctuation)\n",
    "    words_alpha = [word for word in words if word.isalpha()]\n",
    "\n",
    "    # Randomly sample words to replace - i use 2x words just to account for words without synonym\n",
    "    replacement_indices, words_to_replace = sample_words(words_alpha, num_words_to_replace)\n",
    "    #print(replacement_indices)\n",
    "    #print(words_to_replace)\n",
    "    # Create a new sentence with synonyms replaced\n",
    "    words_replaced = 0\n",
    "    new_sentence = []\n",
    "    for word in words:\n",
    "        if word in words_to_replace and words_alpha.index(word) in replacement_indices and words_replaced < num_words_to_replace:\n",
    "            #ask chatGPT for synonym\n",
    "            new_word = ind_syn_ChatGPT(word) \n",
    "            new_sentence.append(new_word)\n",
    "            #operational\n",
    "            all_words.append(word)\n",
    "            words_replaced +=1\n",
    "        else:\n",
    "            new_sentence.append(word)\n",
    "    \n",
    "    return ' '.join(new_sentence)\n",
    "\n",
    "def insert_brackets(phrase, indices):\n",
    "    for i in indices:\n",
    "        if 0 <= i < len(phrase):\n",
    "            phrase[i] = f\"[{phrase[i]}]\"\n",
    "    new_phrase = ' '.join(phrase)\n",
    "    return new_phrase\n",
    "\n",
    "def replace_words_ChatGPT_context(sentence, num_words_to_replace):\n",
    "#get indices of words randomly sampled from sentence/phrase\n",
    "#indices are passed into llm prompting function to replace words given some context. \n",
    "    # Tokenize the sentence\n",
    "    words = word_tokenize(sentence)\n",
    "    # Filter out non-alphabetic tokens (like punctuation)\n",
    "    words_alpha = [word for word in words if word.isalpha()]\n",
    "    \n",
    "    # Randomly sample words to replace - i use 2x words just to account for words without synonym\n",
    "    replacement_indices, words_to_replace = sample_words(words_alpha, num_words_to_replace)\n",
    "    #print(replacement_indices)\n",
    "    #print(words_to_replace)\n",
    "\n",
    "    phrase_to_replace = insert_brackets(words_alpha, replacement_indices)\n",
    "    new_phrase = syn_from_contxt_ChatGPT(phrase_to_replace)\n",
    "    return new_phrase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_data, SOURCES, save_to_json, load_from_json\n",
    "responses, articles, keys = load_data(\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Former government contractor indicted for stealing nuclear materials\n",
      "Roy Lynn Oakley accused of attempting to sell restricted uranium enrichment components\n",
      "Oakley faces up to 10 years in prison and a $250,000 fine per count\n",
      "FBI sting operation prevented the materials from reaching foreign entities\n"
     ]
    }
   ],
   "source": [
    "key = keys[22]\n",
    "random_summary = responses[\"gpt4\"][key]\n",
    "print(random_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------wordNET summary----------\n",
      "Former government declarer indict for thievery atomic materials Roy Lynn Oakley accused of attempting to sell restricted atomic number 92 enrichment components Oakley faces up to 10 years in prison and a $ 250,000 fine per count FBI sting operation prevented the materials from reaching foreign entities\n",
      "-----chatGPT no context summary---\n",
      "previous government contractor indicted because theft nuclear materials Roy Lynn oakley accused of attempting to market restricted uranium enrichment components Oakley faces up to 10 years in prison and a $ 250,000 fine per count FBI sting operation prevented the materials from reaching foreign entities\n",
      "-----GPT with context summary-----\n",
      "Former state employee indicted for pilfering atomic materials Roy Lynn Oakley accused of attempting to sell confidential uranium refinement components Oakley faces up to years in prison and a fine for each count FBI sting operation prevented the materials from reaching foreign entities\n"
     ]
    }
   ],
   "source": [
    "new_summary_wordNET = replace_words_WordNet(random_summary, 5)  # Replace 5of the words\n",
    "new_summary_chatGPT = replace_words_ChatGPT(random_summary, 5)\n",
    "new_summary_chatGPT_context = replace_words_ChatGPT_context(random_summary, 5)\n",
    "print(\"---------wordNET summary----------\")\n",
    "print(new_summary_wordNET)\n",
    "print(\"-----chatGPT no context summary---\")\n",
    "print(new_summary_chatGPT)\n",
    "print(\"-----GPT with context summary-----\")\n",
    "print(new_summary_chatGPT_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: contractor\n",
      "['declarer', 'contractile organ']\n",
      "word: indicted\n",
      "['indict']\n",
      "word: stealing\n",
      "['larceny', 'theft', 'thievery', 'thieving', 'stealth', 'steal', 'steal', 'slip', 'steal']\n",
      "word: nuclear\n",
      "['atomic']\n",
      "word: uranium\n",
      "['U', 'atomic number 92']\n",
      "word: Former\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(all_words)):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword:\u001b[39m\u001b[38;5;124m'\u001b[39m, all_words[i])\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(all_syn[i])\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_words)):\n",
    "    print('word:', all_words[i])\n",
    "    print(all_syn[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply to Dataset and Check Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only suitable for GPT models\n",
    "def generate_gpt_detect_recognition_synonym(\n",
    "    dataset,\n",
    "    model,\n",
    "    starting_idx=0,\n",
    "    detection_type=\"detection\",\n",
    "    replace_synonym = False,\n",
    "    num_words_to_replace = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates detection scores for GPT model outputs compared to other summaries.\n",
    "\n",
    "    This function takes a dataset name, a base model for inference, a starting index \n",
    "    from which to begin enumeration of the dataset, and various options for detection \n",
    "    and synonym replacement. It makes API calls to GPT models using the OpenAI API key \n",
    "    to evaluate the similarity of each summary against all other summaries. If synonym \n",
    "    replacement is enabled, a specified number of words are replaced before comparison.\n",
    "    \n",
    "    The function performs inference using the base model, compares generated summaries \n",
    "    in forward and backward order, and returns a JSON object containing detection results.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): The name of the dataset (e.g., \"cnn\") containing the articles.\n",
    "        model (str): The base model on which inference will be performed.\n",
    "        starting_idx (int, optional): The index to start processing articles from. Defaults to 0.\n",
    "        detection_type (str, optional): The type of detection to perform. Defaults to \"detection\".\n",
    "        replace_synonym (bool, optional): Whether to replace words in the summaries with synonyms. Defaults to False.\n",
    "        num_words_to_replace (int, optional): The number of words to replace with synonyms if `replace_synonym` is True. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        dict: A JSON object containing information about:\n",
    "            - Model compared against\n",
    "            - Key of the article\n",
    "            - Forward detection + probability\n",
    "            - Backward detection + probability\n",
    "            - Overall detection score\n",
    "\n",
    "    \"\"\"\n",
    "    # For retrieving summaries, the specific fine-tuning version isn't needed\n",
    "    exact_model = model\n",
    "    model = \"gpt35\" if model.endswith(\"gpt35\") else model\n",
    "\n",
    "    responses, articles, keys = load_data(dataset)\n",
    "    results = []  # load_from_json(f\"results/{model}_results.json\")\n",
    "\n",
    "    for key in tqdm(keys[starting_idx:], desc=\"Processing keys\"):\n",
    "        article = articles[key]\n",
    "\n",
    "        source_summary = responses[model][key]\n",
    "\n",
    "        # replace synonym\n",
    "        if replace_synonym:\n",
    "            source_summary = replace_words_ChatGPT_context(source_summary, num_words_to_replace)\n",
    "\n",
    "        for other in [s for s in SOURCES if s != model]:\n",
    "            result = {\"key\": key, \"model\": other}\n",
    "            other_summary = responses[other][key]\n",
    "\n",
    "            # Detection\n",
    "            forward_result = get_model_choice(\n",
    "                source_summary,\n",
    "                other_summary,\n",
    "                article,\n",
    "                detection_type,\n",
    "                exact_model,\n",
    "                return_logprobs=True,\n",
    "            )\n",
    "            backward_result = get_model_choice(\n",
    "                other_summary,\n",
    "                source_summary,\n",
    "                article,\n",
    "                detection_type,\n",
    "                exact_model,\n",
    "                return_logprobs=True,\n",
    "            )\n",
    "\n",
    "            forward_choice = forward_result[0].token\n",
    "            backward_choice = backward_result[0].token\n",
    "\n",
    "            result[\"forward_detection\"] = forward_choice\n",
    "            result[\"forward_detection_probability\"] = exp(forward_result[0].logprob)\n",
    "            result[\"backward_detection\"] = backward_choice\n",
    "            result[\"backward_detection_probability\"] = exp(backward_result[0].logprob)\n",
    "\n",
    "            match (forward_choice, backward_choice):\n",
    "                case (\"1\", \"2\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[0].logprob) + exp(backward_result[0].logprob)\n",
    "                    )\n",
    "                case (\"2\", \"1\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[1].logprob) + exp(backward_result[1].logprob)\n",
    "                    )\n",
    "                case (\"1\", \"1\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[0].logprob) + exp(backward_result[1].logprob)\n",
    "                    )\n",
    "                case (\"2\", \"2\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[1].logprob) + exp(backward_result[0].logprob)\n",
    "                    )\n",
    "\n",
    "            results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'claude', 'gpt35', 'gpt4', 'llama']\n",
      "Starting gpt4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing keys:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing keys: 100%|██████████| 50/50 [14:40<00:00, 17.61s/it] \n"
     ]
    }
   ],
   "source": [
    "for model in [\"gpt4\"]:\n",
    "    print(SOURCES)\n",
    "    print(f\"Starting {model}\")\n",
    "    num_synonym = 5\n",
    "    results = generate_gpt_detect_recognition_synonym(\n",
    "        \"cnn\", model,replace_synonym=True, num_words_to_replace=num_synonym, starting_idx=950\n",
    "    )\n",
    "    #Save results\n",
    "    file_name = f\"{model}_results_{num_synonym}_ChatGPT_with_context_50_sentence.json\"\n",
    "    path = os.path.join(\"results\",\"cnn\",\"synonym\",file_name)\n",
    "    save_to_json(results,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR THE OTHER 450 data points\n",
    "def generate_gpt_detect_recognition_synonym(\n",
    "    dataset,\n",
    "    model,\n",
    "    starting_idx=0,\n",
    "    ending_idx=1000,\n",
    "    detection_type=\"detection\",\n",
    "    replace_synonym = False,\n",
    "    num_words_to_replace = 0\n",
    "):\n",
    "\n",
    "    # For retrieving summaries, the specific fine-tuning version isn't needed\n",
    "    exact_model = model\n",
    "    model = \"gpt35\" if model.endswith(\"gpt35\") else model\n",
    "\n",
    "    responses, articles, keys = load_data(dataset)\n",
    "    results = []  # load_from_json(f\"results/{model}_results.json\")\n",
    "\n",
    "    for key in tqdm(keys[starting_idx:ending_idx], desc=\"Processing keys\"):\n",
    "        article = articles[key]\n",
    "\n",
    "        source_summary = responses[model][key]\n",
    "\n",
    "        # replace synonym\n",
    "        if replace_synonym:\n",
    "            source_summary = replace_words_ChatGPT_context(source_summary, num_words_to_replace)\n",
    "\n",
    "        for other in [s for s in SOURCES if s != model]:\n",
    "            result = {\"key\": key, \"model\": other}\n",
    "            other_summary = responses[other][key]\n",
    "\n",
    "            # Detection\n",
    "            forward_result = get_model_choice(\n",
    "                source_summary,\n",
    "                other_summary,\n",
    "                article,\n",
    "                detection_type,\n",
    "                exact_model,\n",
    "                return_logprobs=True,\n",
    "            )\n",
    "            backward_result = get_model_choice(\n",
    "                other_summary,\n",
    "                source_summary,\n",
    "                article,\n",
    "                detection_type,\n",
    "                exact_model,\n",
    "                return_logprobs=True,\n",
    "            )\n",
    "\n",
    "            forward_choice = forward_result[0].token\n",
    "            backward_choice = backward_result[0].token\n",
    "\n",
    "            result[\"forward_detection\"] = forward_choice\n",
    "            result[\"forward_detection_probability\"] = exp(forward_result[0].logprob)\n",
    "            result[\"backward_detection\"] = backward_choice\n",
    "            result[\"backward_detection_probability\"] = exp(backward_result[0].logprob)\n",
    "\n",
    "            match (forward_choice, backward_choice):\n",
    "                case (\"1\", \"2\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[0].logprob) + exp(backward_result[0].logprob)\n",
    "                    )\n",
    "                case (\"2\", \"1\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[1].logprob) + exp(backward_result[1].logprob)\n",
    "                    )\n",
    "                case (\"1\", \"1\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[0].logprob) + exp(backward_result[1].logprob)\n",
    "                    )\n",
    "                case (\"2\", \"2\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[1].logprob) + exp(backward_result[0].logprob)\n",
    "                    )\n",
    "\n",
    "            results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'claude', 'gpt35', 'gpt4', 'llama']\n",
      "Starting gpt4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing keys:   0%|          | 0/450 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing keys: 100%|██████████| 450/450 [2:00:53<00:00, 16.12s/it]    \n"
     ]
    }
   ],
   "source": [
    "for model in [\"gpt4\"]:\n",
    "    print(SOURCES)\n",
    "    print(f\"Starting {model}\")\n",
    "    num_synonym = 5\n",
    "    results = generate_gpt_detect_recognition_synonym(\n",
    "        \"cnn\", model,replace_synonym=True, num_words_to_replace=num_synonym, starting_idx=500, ending_idx=950\n",
    "    )\n",
    "    #Save results\n",
    "    file_name = f\"{model}_results_{num_synonym}_ChatGPT_with_context_450_sentence.json\"\n",
    "    path = os.path.join(\"results\",\"cnn\",\"synonym\",file_name)\n",
    "    save_to_json(results,path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply synonym to 'other' example as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only suitable for GPT models\n",
    "def generate_gpt_detect_recognition_dual_synonym(\n",
    "    dataset,\n",
    "    model,\n",
    "    starting_idx=0,\n",
    "    detection_type=\"detection\",\n",
    "    replace_synonym = False,\n",
    "    num_words_to_replace = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates detection scores for GPT model outputs compared to other summaries using a dual synyonym replacement strategy.\n",
    "\n",
    "    Args:\n",
    "        dataset (str): The name of the dataset (e.g., \"cnn\") containing the articles.\n",
    "        model (str): The base model on which inference will be performed.\n",
    "        starting_idx (int, optional): The index to start processing articles from. Defaults to 0.\n",
    "        detection_type (str, optional): The type of detection to perform. Defaults to \"detection\".\n",
    "        replace_synonym (bool, optional): Whether to replace words in the summaries with synonyms. Defaults to False.\n",
    "        num_words_to_replace (int, optional): The number of words to replace with synonyms if `replace_synonym` is True. Defaults to 0. Replaces the same number in both sentences being compared.\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    # For retrieving summaries, the specific fine-tuning version isn't needed\n",
    "    exact_model = model\n",
    "    model = \"gpt35\" if model.endswith(\"gpt35\") else model\n",
    "\n",
    "    responses, articles, keys = load_data(dataset)\n",
    "    results = []  # load_from_json(f\"results/{model}_results.json\")\n",
    "\n",
    "    for key in tqdm(keys[starting_idx:], desc=\"Processing keys\"):\n",
    "        article = articles[key]\n",
    "\n",
    "        source_summary = responses[model][key]\n",
    "\n",
    "        # replace synonym\n",
    "        if replace_synonym:\n",
    "            source_summary = replace_words_ChatGPT_context(source_summary, num_words_to_replace)\n",
    "\n",
    "        for other in [s for s in SOURCES if s != model]:\n",
    "            result = {\"key\": key, \"model\": other}\n",
    "            other_summary = responses[other][key]\n",
    "\n",
    "            # replace synonym\n",
    "            if replace_synonym:\n",
    "                other_summary = replace_words_ChatGPT_context(other_summary, num_words_to_replace)\n",
    "\n",
    "            # Detection\n",
    "            forward_result = get_model_choice(\n",
    "                source_summary,\n",
    "                other_summary,\n",
    "                article,\n",
    "                detection_type,\n",
    "                exact_model,\n",
    "                return_logprobs=True,\n",
    "            )\n",
    "            backward_result = get_model_choice(\n",
    "                other_summary,\n",
    "                source_summary,\n",
    "                article,\n",
    "                detection_type,\n",
    "                exact_model,\n",
    "                return_logprobs=True,\n",
    "            )\n",
    "\n",
    "            forward_choice = forward_result[0].token\n",
    "            backward_choice = backward_result[0].token\n",
    "\n",
    "            result[\"forward_detection\"] = forward_choice\n",
    "            result[\"forward_detection_probability\"] = exp(forward_result[0].logprob)\n",
    "            result[\"backward_detection\"] = backward_choice\n",
    "            result[\"backward_detection_probability\"] = exp(backward_result[0].logprob)\n",
    "\n",
    "            match (forward_choice, backward_choice):\n",
    "                case (\"1\", \"2\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[0].logprob) + exp(backward_result[0].logprob)\n",
    "                    )\n",
    "                case (\"2\", \"1\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[1].logprob) + exp(backward_result[1].logprob)\n",
    "                    )\n",
    "                case (\"1\", \"1\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[0].logprob) + exp(backward_result[1].logprob)\n",
    "                    )\n",
    "                case (\"2\", \"2\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[1].logprob) + exp(backward_result[0].logprob)\n",
    "                    )\n",
    "\n",
    "            results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'claude', 'gpt35', 'gpt4', 'llama']\n",
      "Starting gpt4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing keys: 100%|██████████| 50/50 [13:25<00:00, 16.10s/it]\n"
     ]
    }
   ],
   "source": [
    "for model in [\"gpt4\"]:\n",
    "    print(SOURCES)\n",
    "    print(f\"Starting {model}\")\n",
    "    num_synonym = 5\n",
    "    results = generate_gpt_detect_recognition_dual_synonym(\n",
    "        \"cnn\", model,replace_synonym=True, num_words_to_replace=num_synonym, starting_idx=950\n",
    "    )\n",
    "    #Save results\n",
    "    file_name = f\"{model}_results_{num_synonym}_ChatGPT_with_context_bothsentences_50_sentence.json\"\n",
    "    path = os.path.join(\"results\",\"cnn\",\"synonym\",file_name)\n",
    "    save_to_json(results,path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding semantically similar indexes in the summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only suitable for GPT models\n",
    "def get_similar_sentence(\n",
    "    dataset,\n",
    "    model,\n",
    "    starting_idx=0,\n",
    "):\n",
    "    exact_model = model\n",
    "    model = \"gpt35\" if model.endswith(\"gpt35\") else model\n",
    "\n",
    "    responses, articles, keys = load_data(dataset)\n",
    "    results = []  # load_from_json(f\"results/{model}_results.json\")\n",
    "\n",
    "    for key in tqdm(keys[starting_idx:], desc=\"Processing keys\"):\n",
    "        summaries = []\n",
    "        result = {\"key\": key}\n",
    "        for other in [s for s in SOURCES]:\n",
    "            summaries.append(responses[other][key])\n",
    "            \n",
    "        result_json = get_gpt_summary_similarity_index(summaries[0],summaries[1],summaries[2],summaries[3],summaries[4])\n",
    "        result[\"indexes\"]= result_json \n",
    "        results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'claude', 'gpt35', 'gpt4', 'llama']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing keys: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': '9177e5ac94f038749e8d4eb526a65461e0f6df4c', 'indexes': '[\"Summary1:0\", \"Summary2:0\", \"Summary3:0\", \"Summary4:0\", \"Summary5:1\"]'}, {'key': 'f12e4bbb07211de7d43b4e331dc73404aa804562', 'indexes': '[\"Summary1:2\", \"Summary2:1\", \"Summary3:2\", \"Summary4:1\", \"Summary5:0\"]'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [\"gpt4\"]:\n",
    "    print(SOURCES)\n",
    "    num_synonym = 2\n",
    "    results = get_similar_sentence(\"cnn\", model, starting_idx=998)\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'key': '9177e5ac94f038749e8d4eb526a65461e0f6df4c',\n",
       "  'indexes': '[\"Summary1:0\", \"Summary2:0\", \"Summary3:0\", \"Summary4:0\", \"Summary5:1\"]'},\n",
       " {'key': 'f12e4bbb07211de7d43b4e331dc73404aa804562',\n",
       "  'indexes': '[\"Summary1:2\", \"Summary2:1\", \"Summary3:2\", \"Summary4:1\", \"Summary5:0\"]'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize what is similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract a record by key\n",
    "def get_record_by_key(results, search_key):\n",
    "    for record in results:\n",
    "        if record['key'] == search_key:\n",
    "            return record\n",
    "    return None  # Return None if key is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract indexes from the record\n",
    "def extract_indexes(record):\n",
    "    if record and 'indexes' in record:\n",
    "        indexes_str = record['indexes']\n",
    "        # Convert the indexes string to a list using json.loads\n",
    "        indexes_list = json.loads(indexes_str)\n",
    "        return indexes_list\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only suitable for GPT models\n",
    "def visualize_similar(\n",
    "    dataset,\n",
    "    model,\n",
    "    starting_idx=0,\n",
    "):\n",
    "    exact_model = model\n",
    "    model = \"gpt35\" if model.endswith(\"gpt35\") else model\n",
    "\n",
    "    responses, articles, keys = load_data(dataset)\n",
    "\n",
    "    for key in tqdm(keys[starting_idx:], desc=\"Processing keys\"):\n",
    "        summaries = []\n",
    "        result = get_record_by_key(results,key)\n",
    "        count = 1\n",
    "        for idx, other in enumerate([s for s in SOURCES]):\n",
    "            print(other)\n",
    "            summary = responses[other][key]\n",
    "            summary = summary.split('\\n')\n",
    "            indexes = extract_indexes(result)\n",
    "            item = indexes[idx]\n",
    "            summary_value = int(item.split(\":\")[1])\n",
    "            summary = summary[summary_value]\n",
    "            print(summary)\n",
    "            \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'claude', 'gpt35', 'gpt4', 'llama']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing keys: 100%|██████████| 2/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human\n",
      "Judge on Heather Mills: Level of premarital wealth \"exaggerated\"\n",
      "claude\n",
      "Judge rejects Mills' claim that she was wealthy before meeting McCartney in 1999\n",
      "gpt35\n",
      "Judge rejects Heather Mills' claim of wealth before marriage to Paul McCartney\n",
      "gpt4\n",
      "Judge finds Heather Mills' claims of wealth in 1999 exaggerated and rejects her portrayal as Paul McCartney's business partner\n",
      "llama\n",
      "Judge finds Mills' wealth exaggerated and her living style unrealistic\n",
      "human\n",
      "President Taylor's daughter married future president of an enemy power\n",
      "claude\n",
      "Elizabeth Harrison Walker, daughter of President Benjamin Harrison, was an economic expert who appeared on radio and TV shows\n",
      "gpt35\n",
      "Elizabeth Harrison Walker: Accomplished woman, lawyer, economist, and media personality\n",
      "gpt4\n",
      "Elizabeth Harrison Walker, daughter of President Benjamin Harrison, became a lawyer and economic expert, appearing on radio and TV\n",
      "llama\n",
      "Sarah Knox Taylor Davis - Died at 21 after falling ill with malaria while visiting her husband's relatives in Louisiana\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [\"gpt4\"]:\n",
    "    print(SOURCES)\n",
    "    visualize_similar(\"cnn\", model, starting_idx=998)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self_recog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
