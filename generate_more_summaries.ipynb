{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- try calling model to generate a summary of an article using same method used for summaries we currently have\n",
    "- adjust code to fit prompt for summary pairwise comparison and try it for one summary\n",
    "- add functions to call qwen, llama, deepseek for generating summaries, then for pairwise comparison - self recognition, self preference\n",
    "- once these functions are verifiesd, move them to appropriate files such as models.py, call them in some file like modify_other_models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximating total number of tokens for xsum/cnn datasets for cost estimate of generating article summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "characters in get_gpt_summary prompt message: 53, about 17.666666666666668 tokens\n",
      "Total characters across cnn_train_articles: 3529529, estimated total # of input tokens = 1176509.6666666667\n",
      "Total characters across xsum_train_articles: 2130600, estimated total of input tokens = 710200.0\n",
      "Total characters across gpt4 cnn summary responses: 374619, estimated total of gpt4 output tokens = 124873.0\n",
      "Total characters across claude cnn responses: 295666, estimated total of claude output tokens = 98555.33333333333\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def count_total_characters(json_file):\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    total_chars = sum(len(article) for article in data.values())\n",
    "    return total_chars\n",
    "\n",
    "cnn_file = \"C:\\\\Users\\\\G34371231\\\\OneDrive - The George Washington University\\\\Desktop\\\\self_recognition\\\\articles\\\\cnn_train_articles.json\" \n",
    "xsum_file = \"C:\\\\Users\\\\G34371231\\\\OneDrive - The George Washington University\\\\Desktop\\\\self_recognition\\\\articles\\\\xsum_train_articles.json\"\n",
    "gpt4_summaries = \"C:\\\\Users\\\\G34371231\\\\OneDrive - The George Washington University\\\\Desktop\\\\self_recognition\\\\summaries\\\\cnn\\\\cnn_train_gpt4_responses.json\"\n",
    "claude_summaries = \"C:\\\\Users\\\\G34371231\\\\OneDrive - The George Washington University\\\\Desktop\\\\self_recognition\\\\summaries\\\\cnn\\\\cnn_train_claude_responses.json\"\n",
    "\n",
    "prompt_string = \"Article: Provide only the summary with no other text.\"\n",
    "print(f'characters in get_gpt_summary prompt message: {len(prompt_string)}, about {len(prompt_string)/3} tokens')\n",
    "gpt_summary_chars = count_total_characters(gpt4_summaries)\n",
    "claude_summary_chars = count_total_characters(claude_summaries)\n",
    "cnn_total_characters = count_total_characters(cnn_file)\n",
    "xsum_total_characters = count_total_characters(xsum_file)\n",
    "print(f\"Total characters across cnn_train_articles: {cnn_total_characters}, estimated total # of input tokens = {cnn_total_characters/3}\")\n",
    "print(f\"Total characters across xsum_train_articles: {xsum_total_characters}, estimated total of input tokens = {xsum_total_characters/3}\")\n",
    "print(f\"Total characters across gpt4 cnn summary responses: {gpt_summary_chars}, estimated total of gpt4 output tokens = {gpt_summary_chars/3}\")\n",
    "print(f\"Total characters across claude cnn responses: {claude_summary_chars}, estimated total of claude output tokens = {claude_summary_chars/3}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self_recog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
