{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install datasets\n",
    "! pip install python-dotenv\n",
    "! pip install openai\n",
    "! pip install anthropic\n",
    "! pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\G25971483\\\\Desktop\\\\Projects\\\\LLM\\\\self_recognition'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\G25971483\\Desktop\\Projects\\LLM\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from data import load_data, SOURCES, save_to_json, load_from_json\n",
    "from models import (\n",
    "    get_gpt_recognition_logprobs,\n",
    "    get_model_choice,\n",
    "    get_logprobs_choice_with_sources,\n",
    "    get_gpt_score,\n",
    ")\n",
    "\n",
    "from math import exp\n",
    "from pprint import pprint\n",
    "from random import shuffle\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_score_results(dataset, model, starting_idx=0):\n",
    "    SCORES = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "\n",
    "    exact_model = model\n",
    "    model = \"gpt35\" if model.endswith(\"gpt35\") else model\n",
    "\n",
    "    responses, articles, keys = load_data(dataset)\n",
    "    results = []\n",
    "\n",
    "    for key in tqdm(keys[starting_idx:], desc=\"Processing keys\"):\n",
    "        article = articles[key]\n",
    "        for target_model in tqdm(SOURCES, desc=\"Processing target models\", leave=False):\n",
    "            summary = responses[target_model][key]\n",
    "            response = get_gpt_score(summary, article, exact_model)\n",
    "            result = {i.token: exp(i.logprob) for i in response if i.token in SCORES}\n",
    "            for score in SCORES:\n",
    "                if score not in result:\n",
    "                    result[score] = 0\n",
    "\n",
    "            results.append(\n",
    "                {\n",
    "                    \"key\": key,\n",
    "                    \"model\": model,\n",
    "                    \"target_model\": target_model,\n",
    "                    \"scores\": result,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# responses[\"gpt4\"]['06352019a19ae31e527f37f7571c6dd7f0c5da37']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing keys: 100%|██████████| 20/20 [00:56<00:00,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': 'bd92eab23374d95ac4430e2e1a8bf7561c662309', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'5': 0.7422421806885163, '4': 0.2573603335519957, '3': 0.0003956113769137268, '2': 1.7079717543507627e-06, '1': 9.457979189875667e-08}}, {'key': 'd84440effc748f9220c7dde068962e803f566bc7', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'4': 0.6675366725947747, '5': 0.3296438004701316, '3': 0.0028128108306324767, '2': 6.298002741428309e-06, '1': 1.314580562613995e-07}}, {'key': 'e2866f596c85b0191ce812260d23855c70a01192', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'4': 0.505405197574499, '5': 0.49409879100322596, '3': 0.000494314798402581, '2': 1.3698285115640545e-06, '1': 7.809061139023033e-08}}, {'key': '4ebd9195bc8c12272b6281a5a610a7b5fb49b8cd', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'5': 0.5580828560942044, '4': 0.4411903032377108, '3': 0.0007239827440845187, '2': 2.445257802256994e-06, '1': 1.0231873939219596e-07}}, {'key': '4bd37aa7004cd1fdf1ccb506d2159a2cf26995e0', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'4': 0.580322613446564, '5': 0.4183544078594466, '3': 0.0013180419696128146, '2': 4.582939286822239e-06, '1': 1.411294898894294e-07}}, {'key': '29b87dc549b8c64b35517e684e79b1da6316bd88', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'5': 0.8115547797441601, '4': 0.1883849317752425, '3': 5.9707495063119476e-05, '2': 3.893827670981688e-07, '1': 3.937853366320189e-08}}, {'key': 'd2f2fe0b8797b416bae71305c9d1c874e2fdd0cc', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'4': 0.6592657257714161, '5': 0.3402138120671081, '3': 0.000519535559654253, '2': 6.345130389769781e-07, '1': 4.646929802248945e-08}}, {'key': '0269d39abbea3edadd225fa97d818f5a789b4c72', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'4': 0.6329398911725366, '5': 0.36596762711434566, '3': 0.0010892422586915114, '2': 3.0927589541534966e-06, '1': 1.0344487239557199e-07}}, {'key': '394f20c9bee9bc8d0e6a65bac48de57bd9f4733d', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'5': 0.8269115851602012, '4': 0.1730440141138104, '3': 4.395975507441474e-05, '2': 2.833120207051641e-07, '1': 3.948586804765788e-08}}, {'key': '6e63c8b1ae01ab91b4832222edaf4bb461b6c568', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'5': 0.5195956687289383, '4': 0.48006373626969673, '3': 0.0003397540787004761, '2': 6.889418273835759e-07, '1': 0}}, {'key': '355875856932fd634aaf7c6b26155403aaf15904', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'4': 0.849792871313852, '5': 0.1414947026078493, '3': 0.008698364147711024, '2': 1.3737778025560279e-05, '1': 1.297038580648144e-07}}, {'key': '999523913d281ab57977d79b644f3879ac4d2e37', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'4': 0.5130197425751138, '5': 0.48604819175886804, '3': 0.0009289394489641598, '2': 2.804214763196693e-06, '1': 1.151723655315116e-07}}, {'key': '5f7424604ec11358dc6fdfa47732f90422949041', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'5': 0.5540721533563532, '4': 0.44551952761571695, '3': 0.0004073514221459079, '2': 8.050254058208134e-07, '1': 5.464937821353634e-08}}, {'key': 'fdb2b65b9cb99b7d52559ae647cae293cb5910d3', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'5': 0.5761809029348058, '4': 0.4236151927944147, '3': 0.0002028686160562211, '2': 6.220303196358456e-07, '1': 0}}, {'key': 'f974fe1b3777ffc5756322c0bb3f31a9b23ec09a', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'4': 0.5505327132340276, '5': 0.4486209307718373, '3': 0.0008436760196807957, '2': 2.3274507222149646e-06, '1': 9.922458705392273e-08}}, {'key': '2930e1a7ac24bce649bfbf5f5971e74515e38a0a', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'5': 0.6635325622007439, '4': 0.3360317598912947, '3': 0.00043347882913286246, '2': 1.789428970321532e-06, '1': 1.0471955131186521e-07}}, {'key': 'f5f7571a69e96c1d288d939861b7216c2bdc0ae4', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'4': 0.6333893240554428, '5': 0.3653476912674477, '3': 0.0012547516681024364, '2': 6.76254675467782e-06, '1': 5.889291200558208e-07}}, {'key': '5f02aa32bd1dc95e47355755398e31550b232f8a', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'5': 0.689273565225005, '4': 0.3106052703886157, '3': 0.00012050768875183243, '2': 3.1793337140597875e-07, '1': 0}}, {'key': '9177e5ac94f038749e8d4eb526a65461e0f6df4c', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'5': 0.6456245926806321, '4': 0.3540356729075955, '3': 0.000337864510281935, '2': 1.5305460359298675e-06, '1': 1.1308037363062234e-07}}, {'key': 'f12e4bbb07211de7d43b4e331dc73404aa804562', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'4': 0.56687766891769, '5': 0.4252346945524878, '3': 0.007757519096209295, '2': 0.00012639280504297574, '1': 3.3148704998217e-06}}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [\"gpt4\"]:\n",
    "    print(model)\n",
    "    results = generate_score_results(\"cnn\", model, starting_idx=980)\n",
    "    print(results)\n",
    "    #save_to_json(results, f\"individual_setting/score_results/cnn/{model}_results.json\")\n",
    "    #print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'bd92eab23374d95ac4430e2e1a8bf7561c662309', 'model': 'gpt4', 'target_model': 'gpt4', 'scores': {'5': 0.7422421806885163, '4': 0.2573603335519957, '3': 0.0003956113769137268, '2': 1.7079717543507627e-06, '1': 9.457979189875667e-08}}\n"
     ]
    }
   ],
   "source": [
    "print(results[0]) # 0.57 $ for 20 articles in individual comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for Pairwise Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only suitable for GPT models\n",
    "def generate_gpt_logprob_results(\n",
    "    dataset,\n",
    "    model,\n",
    "    starting_idx=0,\n",
    "    detection_type=\"detection\",\n",
    "    comparison_type=\"comparison\",\n",
    "):\n",
    "    # For retrieving summaries, the specific fine-tuning version isn't needed\n",
    "    exact_model = model\n",
    "    model = \"gpt35\" if model.endswith(\"gpt35\") else model\n",
    "\n",
    "    responses, articles, keys = load_data(dataset)\n",
    "    results = []  # load_from_json(f\"results/{model}_results.json\")\n",
    "\n",
    "    for key in tqdm(keys[starting_idx:], desc=\"Processing keys\"):\n",
    "        article = articles[key]\n",
    "\n",
    "        source_summary = responses[model][key]\n",
    "        for other in [s for s in SOURCES if s != model]:\n",
    "            result = {\"key\": key, \"model\": other}\n",
    "            other_summary = responses[other][key]\n",
    "\n",
    "            # Detection\n",
    "            forward_result = get_model_choice(\n",
    "                source_summary,\n",
    "                other_summary,\n",
    "                article,\n",
    "                detection_type,\n",
    "                exact_model,\n",
    "                return_logprobs=True,\n",
    "            )\n",
    "            backward_result = get_model_choice(\n",
    "                other_summary,\n",
    "                source_summary,\n",
    "                article,\n",
    "                detection_type,\n",
    "                exact_model,\n",
    "                return_logprobs=True,\n",
    "            )\n",
    "\n",
    "            forward_choice = forward_result[0].token\n",
    "            backward_choice = backward_result[0].token\n",
    "\n",
    "            result[\"forward_detection\"] = forward_choice\n",
    "            result[\"forward_detection_probability\"] = exp(forward_result[0].logprob)\n",
    "            result[\"backward_detection\"] = backward_choice\n",
    "            result[\"backward_detection_probability\"] = exp(backward_result[0].logprob)\n",
    "\n",
    "            match (forward_choice, backward_choice):\n",
    "                case (\"1\", \"2\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[0].logprob) + exp(backward_result[0].logprob)\n",
    "                    )\n",
    "                case (\"2\", \"1\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[1].logprob) + exp(backward_result[1].logprob)\n",
    "                    )\n",
    "                case (\"1\", \"1\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[0].logprob) + exp(backward_result[1].logprob)\n",
    "                    )\n",
    "                case (\"2\", \"2\"):\n",
    "                    result[\"detection_score\"] = 0.5 * (\n",
    "                        exp(forward_result[1].logprob) + exp(backward_result[0].logprob)\n",
    "                    )\n",
    "\n",
    "            # Comparison\n",
    "            forward_result = get_model_choice(\n",
    "                source_summary,\n",
    "                other_summary,\n",
    "                article,\n",
    "                comparison_type,\n",
    "                exact_model,\n",
    "                return_logprobs=True,\n",
    "            )\n",
    "            backward_result = get_model_choice(\n",
    "                other_summary,\n",
    "                source_summary,\n",
    "                article,\n",
    "                comparison_type,\n",
    "                exact_model,\n",
    "                return_logprobs=True,\n",
    "            )\n",
    "\n",
    "            forward_choice = forward_result[0].token\n",
    "            backward_choice = backward_result[0].token\n",
    "\n",
    "            # If the comparison asked \"Which is worse?\" then reverse the options\n",
    "            if comparison_type == \"comparison_with_worse\":\n",
    "                forward_choice = \"1\" if forward_choice == \"2\" else \"2\"\n",
    "                backward_choice = \"1\" if backward_choice == \"2\" else \"2\"\n",
    "\n",
    "            result[\"forward_comparison\"] = forward_choice\n",
    "            result[\"forward_comparison_probability\"] = exp(forward_result[0].logprob)\n",
    "            result[\"backward_comparison\"] = backward_choice\n",
    "            result[\"backward_comparison_probability\"] = exp(backward_result[0].logprob)\n",
    "\n",
    "            match (forward_choice, backward_choice):\n",
    "                case (\"1\", \"2\"):\n",
    "                    result[\"self_preference\"] = 0.5 * (\n",
    "                        exp(forward_result[0].logprob) + exp(backward_result[0].logprob)\n",
    "                    )\n",
    "                case (\"2\", \"1\"):\n",
    "                    result[\"self_preference\"] = 0.5 * (\n",
    "                        exp(forward_result[1].logprob) + exp(backward_result[1].logprob)\n",
    "                    )\n",
    "                case (\"1\", \"1\"):\n",
    "                    result[\"self_preference\"] = 0.5 * (\n",
    "                        exp(forward_result[0].logprob) + exp(backward_result[1].logprob)\n",
    "                    )\n",
    "                case (\"2\", \"2\"):\n",
    "                    result[\"self_preference\"] = 0.5 * (\n",
    "                        exp(forward_result[1].logprob) + exp(backward_result[0].logprob)\n",
    "                    )\n",
    "\n",
    "            results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['human', 'claude', 'gpt35', 'gpt4', 'llama']\n",
      "Starting gpt4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing keys: 100%|██████████| 2/2 [04:59<00:00, 149.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'key': '9177e5ac94f038749e8d4eb526a65461e0f6df4c', 'model': 'human', 'forward_detection': '1', 'forward_detection_probability': 0.7095165758036815, 'backward_detection': '1', 'detection_score': 0.566544069240114, 'forward_comparison': '1', 'forward_comparison_probability': 0.9991200103182194, 'backward_comparison': '2', 'backward_comparison_probability': 0.9978128770465099, 'self_preference': 0.9984664436823647}, {'key': '9177e5ac94f038749e8d4eb526a65461e0f6df4c', 'model': 'claude', 'forward_detection': '1', 'forward_detection_probability': 0.6985912162845513, 'backward_detection': '1', 'detection_score': 0.4960112491432166, 'forward_comparison': '1', 'forward_comparison_probability': 0.8605825976198661, 'backward_comparison': '2', 'backward_comparison_probability': 0.792832859043062, 'self_preference': 0.8267077283314641}, {'key': '9177e5ac94f038749e8d4eb526a65461e0f6df4c', 'model': 'gpt35', 'forward_detection': '1', 'forward_detection_probability': 0.758313166685928, 'backward_detection': '1', 'detection_score': 0.6110940275855147, 'forward_comparison': '1', 'forward_comparison_probability': 0.9999872900832717, 'backward_comparison': '2', 'backward_comparison_probability': 0.9993217492161197, 'self_preference': 0.9996545196496958}, {'key': '9177e5ac94f038749e8d4eb526a65461e0f6df4c', 'model': 'llama', 'forward_detection': '1', 'forward_detection_probability': 0.742376375359432, 'backward_detection': '1', 'detection_score': 0.5146790991399695, 'forward_comparison': '1', 'forward_comparison_probability': 0.973890663280048, 'backward_comparison': '2', 'backward_comparison_probability': 0.9808893743718521, 'self_preference': 0.9773900188259501}, {'key': 'f12e4bbb07211de7d43b4e331dc73404aa804562', 'model': 'human', 'forward_detection': '1', 'forward_detection_probability': 0.7276529219737985, 'backward_detection': '2', 'detection_score': 0.6426341614198274, 'forward_comparison': '1', 'forward_comparison_probability': 0.7671934062611188, 'backward_comparison': '2', 'backward_comparison_probability': 0.6688261219732707, 'self_preference': 0.7180097641171947}, {'key': 'f12e4bbb07211de7d43b4e331dc73404aa804562', 'model': 'claude', 'forward_detection': '1', 'forward_detection_probability': 0.6985056371169033, 'backward_detection': '2', 'detection_score': 0.6393618835403101, 'forward_comparison': '1', 'forward_comparison_probability': 0.9936694190994969, 'backward_comparison': '2', 'backward_comparison_probability': 0.889257868255374, 'self_preference': 0.9414636436774355}, {'key': 'f12e4bbb07211de7d43b4e331dc73404aa804562', 'model': 'gpt35', 'forward_detection': '1', 'forward_detection_probability': 0.6272464834805158, 'backward_detection': '1', 'detection_score': 0.5430830756230252, 'forward_comparison': '1', 'forward_comparison_probability': 0.5798613011427564, 'backward_comparison': '2', 'backward_comparison_probability': 0.5929352360675793, 'self_preference': 0.5863982686051679}, {'key': 'f12e4bbb07211de7d43b4e331dc73404aa804562', 'model': 'llama', 'forward_detection': '1', 'forward_detection_probability': 0.6864455584347335, 'backward_detection': '1', 'detection_score': 0.5248455046566877, 'forward_comparison': '1', 'forward_comparison_probability': 0.6272588403579552, 'backward_comparison': '2', 'backward_comparison_probability': 0.5811942155114143, 'self_preference': 0.6042265279346848}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [\"gpt4\"]:\n",
    "    print(SOURCES)\n",
    "    print(f\"Starting {model}\")\n",
    "    results = generate_gpt_logprob_results(\n",
    "        \"cnn\", model, comparison_type=\"comparison_with_worse\", starting_idx=998\n",
    "    )\n",
    "    #save_to_json(results, f\"results_with_worse/cnn/{model}_results.json\")\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'key': '9177e5ac94f038749e8d4eb526a65461e0f6df4c',\n",
       "  'model': 'human',\n",
       "  'forward_detection': '1',\n",
       "  'forward_detection_probability': 0.7095165758036815,\n",
       "  'backward_detection': '1',\n",
       "  'detection_score': 0.566544069240114,\n",
       "  'forward_comparison': '1',\n",
       "  'forward_comparison_probability': 0.9991200103182194,\n",
       "  'backward_comparison': '2',\n",
       "  'backward_comparison_probability': 0.9978128770465099,\n",
       "  'self_preference': 0.9984664436823647},\n",
       " {'key': '9177e5ac94f038749e8d4eb526a65461e0f6df4c',\n",
       "  'model': 'claude',\n",
       "  'forward_detection': '1',\n",
       "  'forward_detection_probability': 0.6985912162845513,\n",
       "  'backward_detection': '1',\n",
       "  'detection_score': 0.4960112491432166,\n",
       "  'forward_comparison': '1',\n",
       "  'forward_comparison_probability': 0.8605825976198661,\n",
       "  'backward_comparison': '2',\n",
       "  'backward_comparison_probability': 0.792832859043062,\n",
       "  'self_preference': 0.8267077283314641},\n",
       " {'key': '9177e5ac94f038749e8d4eb526a65461e0f6df4c',\n",
       "  'model': 'gpt35',\n",
       "  'forward_detection': '1',\n",
       "  'forward_detection_probability': 0.758313166685928,\n",
       "  'backward_detection': '1',\n",
       "  'detection_score': 0.6110940275855147,\n",
       "  'forward_comparison': '1',\n",
       "  'forward_comparison_probability': 0.9999872900832717,\n",
       "  'backward_comparison': '2',\n",
       "  'backward_comparison_probability': 0.9993217492161197,\n",
       "  'self_preference': 0.9996545196496958},\n",
       " {'key': '9177e5ac94f038749e8d4eb526a65461e0f6df4c',\n",
       "  'model': 'llama',\n",
       "  'forward_detection': '1',\n",
       "  'forward_detection_probability': 0.742376375359432,\n",
       "  'backward_detection': '1',\n",
       "  'detection_score': 0.5146790991399695,\n",
       "  'forward_comparison': '1',\n",
       "  'forward_comparison_probability': 0.973890663280048,\n",
       "  'backward_comparison': '2',\n",
       "  'backward_comparison_probability': 0.9808893743718521,\n",
       "  'self_preference': 0.9773900188259501},\n",
       " {'key': 'f12e4bbb07211de7d43b4e331dc73404aa804562',\n",
       "  'model': 'human',\n",
       "  'forward_detection': '1',\n",
       "  'forward_detection_probability': 0.7276529219737985,\n",
       "  'backward_detection': '2',\n",
       "  'detection_score': 0.6426341614198274,\n",
       "  'forward_comparison': '1',\n",
       "  'forward_comparison_probability': 0.7671934062611188,\n",
       "  'backward_comparison': '2',\n",
       "  'backward_comparison_probability': 0.6688261219732707,\n",
       "  'self_preference': 0.7180097641171947},\n",
       " {'key': 'f12e4bbb07211de7d43b4e331dc73404aa804562',\n",
       "  'model': 'claude',\n",
       "  'forward_detection': '1',\n",
       "  'forward_detection_probability': 0.6985056371169033,\n",
       "  'backward_detection': '2',\n",
       "  'detection_score': 0.6393618835403101,\n",
       "  'forward_comparison': '1',\n",
       "  'forward_comparison_probability': 0.9936694190994969,\n",
       "  'backward_comparison': '2',\n",
       "  'backward_comparison_probability': 0.889257868255374,\n",
       "  'self_preference': 0.9414636436774355},\n",
       " {'key': 'f12e4bbb07211de7d43b4e331dc73404aa804562',\n",
       "  'model': 'gpt35',\n",
       "  'forward_detection': '1',\n",
       "  'forward_detection_probability': 0.6272464834805158,\n",
       "  'backward_detection': '1',\n",
       "  'detection_score': 0.5430830756230252,\n",
       "  'forward_comparison': '1',\n",
       "  'forward_comparison_probability': 0.5798613011427564,\n",
       "  'backward_comparison': '2',\n",
       "  'backward_comparison_probability': 0.5929352360675793,\n",
       "  'self_preference': 0.5863982686051679},\n",
       " {'key': 'f12e4bbb07211de7d43b4e331dc73404aa804562',\n",
       "  'model': 'llama',\n",
       "  'forward_detection': '1',\n",
       "  'forward_detection_probability': 0.6864455584347335,\n",
       "  'backward_detection': '1',\n",
       "  'detection_score': 0.5248455046566877,\n",
       "  'forward_comparison': '1',\n",
       "  'forward_comparison_probability': 0.6272588403579552,\n",
       "  'backward_comparison': '2',\n",
       "  'backward_comparison_probability': 0.5811942155114143,\n",
       "  'self_preference': 0.6042265279346848}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
